
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>A variational autoencoder for 20CR &#8212; Machine Learning GCM</title>
    <link rel="stylesheet" href="../../_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Source code for the variational autoencoder" href="source.html" />
    <link rel="prev" title="Normalisation library" href="../../lib/normalise.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="source.html" title="Source code for the variational autoencoder"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="../../lib/normalise.html" title="Normalisation library"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">ML GCM</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="../../index.html">
              <img class="logo" src="../../_static/Weather-Network.png" alt="Logo"/>
            </a></p>
<h3><a href="../../index.html">Table of Contents</a></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../visualisation/MO_global_analysis/index.html"> Big data: Near-surface temperature, wind, and precipitation, from the Met Office global analysis</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../visualisation/20CRv2c_global_analysis/index.html"> Medium-sized data: Near-surface temperature, wind, and mean-sea-level pressure, from the Twentieth Century Reanalysis version 2c</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../data/download.html">Download training data</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../data/conversion.html">Process training data for TensorFlow</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">A variational autoencoder</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../visualisation/20CRv2c_latent_space/index.html"> Small data: Near-surface temperature, wind, and mean-sea-level pressure, from the Twentieth Century Reanalysis version 2c, after compression into a 100-dimensional latent space.</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../generator/generator.html">A generative model</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../predictor/index.html">A +6hr predictor</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../GCM/index.html">A Machine-Learning GCM using the +6hr predictor</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../visualisation/GCM_video/index.html"> Simulated data: Near-surface temperature, wind, and mean-sea-level pressure, from the Machine-Learning GCM.</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../presentations/index.html">Presentation decks and poster</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../credits.html">Small Print</a></li>
</ul>
<h3><a href="https://github.com/philip-brohan/ML_GCM">Get the source code</a></h3>

<a href="https://github.com/philip-brohan/ML_GCM"
           rel="nofollow">Github source repository</a>

<h3>Found a bug, or have a suggestion?</h3>

Please <a href="https://github.com/philip-brohan/ML_GCM/issues/new">raise an issue</a>.
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="a-variational-autoencoder-for-20cr">
<h1>A variational autoencoder for 20CR<a class="headerlink" href="#a-variational-autoencoder-for-20cr" title="Permalink to this headline">¶</a></h1>
<p>An <a class="reference external" href="https://en.wikipedia.org/wiki/Autoencoder">autoencoder</a> is a pair of <a class="reference external" href="https://en.wikipedia.org/wiki/Artificial_neural_network">neural nets</a>: one of them (the <cite>encoder</cite>) compresses an input field into a low-dimensional ‘latent space’, and the other (the <cite>generator</cite> or <cite>decoder</cite>) expands the small latent space representation back into the input field. They are trained as a pair - optimising to make <code class="docutils literal notranslate"><span class="pre">generator(encoder(input))</span></code> as close to the original <code class="docutils literal notranslate"><span class="pre">input</span></code> as possible. Effectively an autoencoder learns an effective compressed representation of the original data.</p>
<p>A <a class="reference external" href="https://en.wikipedia.org/wiki/Autoencoder#Variational_autoencoder_(VAE)">variational autoencoder</a> is an autoencoder where the generator network can be used independently of the encoder to generate new states similar to the original inputs. This means constraining the latent space to be continuous (two close points in the latent space should produce two similar states when decoded), and complete (any point sampled from the latent space should give ‘meaningful’ content once decoded).</p>
<p>After <a class="reference external" href="http://brohan.org/Machine-Learning/">some experimentation</a> I chose an autoencoder with eight convolutional layers, encoding the features as a 100-dimensional latent space. I failed to get the <a class="reference external" href="https://www.kaggle.com/vikramtiwari/autoencoders-using-tf-keras-mnist">traditional variational autoencoder design</a> to work, so I adopted a simpler approach: regularising the latent space by explicitly forcing it to have zero mean and unit standard deviation, and perturbing it with gaussian noise.</p>
<div class="figure align-center" id="id1" style="width: 95%">
<a class="reference internal image-reference" href="../../_images/autoencoder.png"><img alt="../../_images/autoencoder.png" src="../../_images/autoencoder.png" style="width: 95%;" /></a>
<p class="caption"><span class="caption-text">Model structure for the variational autoencoder (<a class="reference internal" href="source.html"><span class="doc">Source code</span></a>).</span></p>
</div>
<p>The autoencoder is specified as five models:</p>
<ul class="simple">
<li>An encoder</li>
<li>A generator</li>
<li>A noise model</li>
<li>An autoencoder = generator(encoder())</li>
<li>A variational autoencoder = generator(noise(encoder()))</li>
</ul>
<p>Then training the variational autoencoder model sets the weights in the encoder and the generator, while maintaining a regularised latent space, and we can deploy the <a class="reference internal" href="../../visualisation/20CRv2c_latent_space/index.html"><span class="doc">autoencoder (without noise)</span></a> and <a class="reference internal" href="../generator/generator.html"><span class="doc">generator</span></a> models using those weights.</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="source.html">Source code for the variational autoencoder</a></li>
</ul>
</div>
<p>To test the model, run the autoencoder on 20CRv2c fields not used in the training process:</p>
<div class="figure align-center" id="id2" style="width: 95%">
<a class="reference internal image-reference" href="../../_images/compare_tpuv.png"><img alt="../../_images/compare_tpuv.png" src="../../_images/compare_tpuv.png" style="width: 95%;" /></a>
<p class="caption"><span class="caption-text">Validation of the autoencoder. Top panel: T2m, mslp, u and v winds in the original 20CRv3 (at one point in time). Botom panel: same, but after autoencoding. The four scatter-plots compare orignal and encoded values for the four variables. (<a class="reference internal" href="validation_source.html"><span class="doc">Validation source code</span></a>).</span></p>
</div>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="validation_source.html">Source code for the autoencoder validation</a></li>
</ul>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="source.html" title="Source code for the variational autoencoder"
             >next</a> |</li>
        <li class="right" >
          <a href="../../lib/normalise.html" title="Normalisation library"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../index.html">ML GCM</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    </div>
  </body>
</html>